[TOC]

# 数据采集

数据采集主要是分两个模块：业务数据和用户日志数据

主要分为实时增量和历史全量，实时增量的用户日志数据通过flume采集到kafka，实时增量的业务数据通过maxwell同步到kafka；历史全量数据通过datax同步到HDFS，即Hive里

## 1.用户日志数据

### 1.1来源

用户日志数据来源于自己编写的日志数据模拟器生成，通过flume配置kafka channel 实时增量采集到kafka的topic_log主题里，准备后续Flink的计算。

### 1.2配置

- 1.将application.yml、gmall2020-mock-log-2021-10-10.jar、path.json、logback.xml上传到Flink01的opt/module/applog目录下

  ```shell
  mkdir /opt/module/applog
  ```

上传文件到/opt/module/applog目录

- 2.修改配置文件application.yml，可以根据需求生成对应日期的用户行为日志

  ```yaml
  # 外部配置打开
  logging.config: "./logback.xml"
  #业务日期  注意：并不是Linux系统生成日志的日期，而是生成数据中的时间
  mock.date: "2022-06-14"(这里可以根据需求进行修改)
  #模拟数据发送模式
  #mock.type: "http"
  #mock.type: "kafka"
  mock.type: "log"
  
  #http模式下，发送的地址
  mock.url: "http://hdp1/applog"
  
  #kafka模式下，发送的地址
  mock:
    kafka-server: "hdp1:9092,hdp2:9092,hdp3:9092"
    kafka-topic: "ODS_BASE_LOG"
  
  #启动次数
  mock.startup.count: 200
  #设备最大值
  mock.max.mid: 500000
  #会员最大值
  mock.max.uid: 100
  #商品最大值
  mock.max.sku-id: 35
  #页面平均访问时间
  mock.page.during-time-ms: 20000
  #错误概率 百分比
  mock.error.rate: 3
  #每条日志发送延迟 ms
  mock.log.sleep: 10
  #商品详情来源  用户查询，商品推广，智能推荐, 促销活动
  mock.detail.source-type-rate: "40:25:15:20"
  #领取购物券概率
  mock.if_get_coupon_rate: 75
  #购物券最大id
  mock.max.coupon-id: 3
  #搜索关键词  
  mock.search.keyword: "图书,小米,iphone11,电视,口红,ps5,苹果手机,小米盒子"
  ```

- 3.修改logback文件

  修改日志数据生成的路径，生成的日志文件格式：app.yyyy-MM-dd.log

  ```shell
  <property name="LOG_HOME" value="/opt/module/applog/log" />
  ```

- 4.用户日志数据模拟已写成脚本

  ```shell
  lg.sh(直接运行脚本即可,会生成一批数据文件到applog目录下)
  ```

## 2.业务数据

### 2.1来源

业务数据来源于数据模拟器,模拟器会实时向数据库中更新,插入数据,模拟实时增量场景，maxwell实时抓取binlog同步到kafka的topic_db主题里，准备后续计算。

### 2.2配置

业务数据存在MySQL里，将"Flink+Kafka实时数仓\模拟数据\业务数据\gmall.sql"文件通过数据库工具执行，先创建gmall数据库再执行，先将库表准备好

- 1.在Flink01的/opt/module目录下创建db_log目录

- 2.把"Flink+Kafka实时数仓\模拟数据\业务数据"下其他两个文件上传上去

- 3.根据需求修改application.properties配置

  ```shell
  spring.datasource.driver-class-name=com.mysql.jdbc.Driver
  spring.datasource.url=jdbc:mysql://Flink01:3306/gmall?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=GMT%2B8
  spring.datasource.username=root
  spring.datasource.password=123456
  logging.pattern.console=%m%n
  mybatis-plus.global-config.db-config.field-strategy=not_null
  
  #业务日期
  mock.date=2022-11-10(这里可以根据需求进行更改,如果你想明显得验证得话可以改成当日时间)
  #是否重置  注意：第一次执行必须设置为1，后续不需要重置不用设置为1
  mock.clear=1
  #是否重置用户 注意：第一次执行必须设置为1，后续不需要重置不用设置为1
  mock.clear.user=1
  ```

- 4.在db_log目录下执行命令，生成2022-11-10日的业务数据

  ```shell
  java -jar gmall2020-mock-db-2021-11-14.jar
  ```

- 5.查看gmall，是否有2022-11-10日的业务数据

## 3.采集用户日志数据

## 4.采集业务数据

## 5.注意事项

/opt/module/db_log/application.properties

 /opt/module/applog/application.yml

/opt/module/maxwell/config.properties

这三个文件里的mock_data应该都是一致，你想模拟哪一天的数据就写哪一天，对于增量而言，日期比较的重要，对于全量而言，模拟的日期就不是很重要，反正是全量同步，当前包括历史的
